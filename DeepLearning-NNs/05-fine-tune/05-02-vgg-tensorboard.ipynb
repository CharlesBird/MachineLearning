{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n调参技巧\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "调参技巧\n",
    "\"\"\"\n",
    "# 可视化\n",
    "# fine-tune\n",
    "# 优化算法、激活函数、初始化函数\n",
    "# 批归一化\n",
    "# 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard\n",
    "# 1. 指定面板图上显示的变量\n",
    "# 2. 训练过程中将这些变量计算出来，输出到文件中\n",
    "# 3. 文件解析 ./tensorboard --logdir=dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batches.meta', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'readme.html', 'test_batch']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "CIFAR_DIR = './../cifar-10-batches-py'\n",
    "print(os.listdir(CIFAR_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n",
      "(10000, 3072)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f, encoding='bytes')\n",
    "        return data[b'data'], data[b'labels']\n",
    "\n",
    "class CifarData:\n",
    "    def __init__(self, filenames, need_shuffle):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for filename in filenames:\n",
    "            data, labels = load_data(filename)\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 - 1  # 为了提高预测准确率，需要对数据进行归一化\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "        print(self._labels.shape)\n",
    "        \n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0  # 当前数据集指明遍历的位置\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "    \n",
    "    def _shuffle_data(self):\n",
    "        p = np.random.permutation(self._num_examples)  # 索引进行混排\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"返回batch_size个样本\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
    "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = CifarData(train_filenames, True)\n",
    "test_data = CifarData(test_filenames, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-a147d056956e>:20: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From D:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4F6CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4F6CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4F6CC8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4F6CC8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-5-a147d056956e>:31: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCE3A0708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCE3A0708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCE3A0708>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCE3A0708>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4EB4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4EB4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4EB4C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF4EB4C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCF7AA088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCF7AA088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCF7AA088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBCF7AA088>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF51C308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF51C308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF51C308>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBCF51C308>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x000001DBC60A1D88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBC8A793C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBC8A793C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBC8A793C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x000001DBC8A793C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-5-a147d056956e>:46: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001DBCF7B5908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001DBCF7B5908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001DBCF7B5908>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001DBCF7B5908>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From <ipython-input-5-a147d056956e>:49: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001DBC8A793C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001DBC8A793C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001DBC8A793C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001DBC8A793C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From D:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# 计算图模型，先新建计算图，然后将数据塞入计算图中\n",
    "# placeholder 占位符的作用\n",
    "x = tf.placeholder(tf.float32, [None, 3072])  # None 样本数不确定，mini_batch\n",
    "# [None]\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# 图片转换，reshape\n",
    "x_image = tf.reshape(x, [-1, 3, 32, 32])\n",
    "# 大小： 32*32\n",
    "x_image = tf.transpose(x_image, perm=[0, 2, 3, 1])\n",
    "\n",
    "# 第一个卷积层\n",
    "# 参数说明\n",
    "# - 32: 卷积层输出的通道数目\n",
    "# - (3, 3): 卷积核的大小\n",
    "# - padding: 类型有两种 same|valid，same的话使得输出的图像大小不会变化\n",
    "# - activation: 激活函数\n",
    "# - name: 给这一层做一个命名，将图打印出来有意义的的一个图\n",
    "# conv1: 神经元图，feature_map, 输出图像\n",
    "conv1_1 = tf.layers.conv2d(x_image, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv1_1')\n",
    "\n",
    "conv1_2 = tf.layers.conv2d(conv1_1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv1_2')\n",
    "\n",
    "# pooling 池化层\n",
    "# 参数说明\n",
    "# - conv1: 输入参数\n",
    "# - (2, 2): kernal size\n",
    "# - (2, 3): 步长 (stride)\n",
    "# - name: 给这一层做一个命名，将图打印出来有意义的的一个图\n",
    "# 大小： 16*16\n",
    "pooling1 = tf.layers.max_pooling2d(conv1_2, (2, 2), (2, 2), name='pool1')\n",
    "\n",
    "conv2_1 = tf.layers.conv2d(pooling1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv2_1')\n",
    "\n",
    "conv2_2 = tf.layers.conv2d(conv2_1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv2_2')\n",
    "# 大小： 8*8\n",
    "pooling2 = tf.layers.max_pooling2d(conv2_2, (2, 2), (2, 2), name='pool2')\n",
    "\n",
    "conv3_1 = tf.layers.conv2d(pooling2, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv3_1')\n",
    "conv3_2 = tf.layers.conv2d(conv3_1, 32, (3, 3), padding='same', activation=tf.nn.relu, name='conv3_2')\n",
    "# 大小： 4*4*32\n",
    "pooling3 = tf.layers.max_pooling2d(conv3_2, (2, 2), (2, 2), name='pool3')\n",
    "\n",
    "# 做一个展平\n",
    "# 展平后的shape: [None, 4*4*32]\n",
    "flatten = tf.layers.flatten(pooling3)\n",
    "\n",
    "# 全连接层，使它能够映射到10个类别上去\n",
    "y_ = tf.layers.dense(flatten, 10)\n",
    "\n",
    "# 交叉熵损失数函数\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "# 执行原理\n",
    "# y_ -> softmax\n",
    "# y -> one_hot\n",
    "# loss -> ylogy_\n",
    "\n",
    "# 寻找最大概率值的 indices\n",
    "# 1 代表在第一个维度上\n",
    "predict = tf.argmax(y_, 1)\n",
    "# correct_prediction 结果可能是[0,1,0,0,1,1,1]\n",
    "correct_prediction = tf.equal(predict, y)\n",
    "# 求准确率，就是求平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "# 在我们有了目标函数和损失函数，再定义梯度下降方法\n",
    "# 梯度下降的变种\n",
    "# 优化最小loss的值\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "# 计算图构建完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 100, loss: 1.85634, acc: 0.35000\n",
      "[Train] Step: 200, loss: 1.86575, acc: 0.45000\n",
      "[Train] Step: 300, loss: 1.78467, acc: 0.40000\n",
      "[Train] Step: 400, loss: 1.87614, acc: 0.30000\n",
      "[Train] Step: 500, loss: 1.91084, acc: 0.25000\n",
      "[Train] Step: 600, loss: 1.55235, acc: 0.25000\n",
      "[Train] Step: 700, loss: 1.63955, acc: 0.40000\n",
      "[Train] Step: 800, loss: 1.65670, acc: 0.40000\n",
      "[Train] Step: 900, loss: 1.60237, acc: 0.45000\n",
      "[Train] Step: 1000, loss: 1.51815, acc: 0.55000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 1000, acc: 0.51750\n",
      "[Train] Step: 1100, loss: 1.28620, acc: 0.50000\n",
      "[Train] Step: 1200, loss: 1.13470, acc: 0.50000\n",
      "[Train] Step: 1300, loss: 1.19133, acc: 0.65000\n",
      "[Train] Step: 1400, loss: 1.50159, acc: 0.40000\n",
      "[Train] Step: 1500, loss: 1.64293, acc: 0.45000\n",
      "[Train] Step: 1600, loss: 1.70861, acc: 0.35000\n",
      "[Train] Step: 1700, loss: 1.32741, acc: 0.45000\n",
      "[Train] Step: 1800, loss: 1.04880, acc: 0.70000\n",
      "[Train] Step: 1900, loss: 1.01060, acc: 0.65000\n",
      "[Train] Step: 2000, loss: 1.13868, acc: 0.50000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 2000, acc: 0.57900\n",
      "[Train] Step: 2100, loss: 1.02376, acc: 0.65000\n",
      "[Train] Step: 2200, loss: 1.04039, acc: 0.65000\n",
      "[Train] Step: 2300, loss: 1.44119, acc: 0.50000\n",
      "[Train] Step: 2400, loss: 0.95237, acc: 0.65000\n",
      "[Train] Step: 2500, loss: 0.69227, acc: 0.85000\n",
      "[Train] Step: 2600, loss: 1.30442, acc: 0.40000\n",
      "[Train] Step: 2700, loss: 0.47155, acc: 0.80000\n",
      "[Train] Step: 2800, loss: 1.02411, acc: 0.55000\n",
      "[Train] Step: 2900, loss: 1.31957, acc: 0.55000\n",
      "[Train] Step: 3000, loss: 1.06025, acc: 0.70000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 3000, acc: 0.64200\n",
      "[Train] Step: 3100, loss: 0.77441, acc: 0.75000\n",
      "[Train] Step: 3200, loss: 0.86378, acc: 0.65000\n",
      "[Train] Step: 3300, loss: 0.52486, acc: 0.80000\n",
      "[Train] Step: 3400, loss: 0.76909, acc: 0.70000\n",
      "[Train] Step: 3500, loss: 1.04252, acc: 0.60000\n",
      "[Train] Step: 3600, loss: 0.65747, acc: 0.75000\n",
      "[Train] Step: 3700, loss: 1.13135, acc: 0.60000\n",
      "[Train] Step: 3800, loss: 0.85051, acc: 0.60000\n",
      "[Train] Step: 3900, loss: 0.87991, acc: 0.70000\n",
      "[Train] Step: 4000, loss: 1.12107, acc: 0.60000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 4000, acc: 0.65550\n",
      "[Train] Step: 4100, loss: 1.01996, acc: 0.60000\n",
      "[Train] Step: 4200, loss: 1.02162, acc: 0.75000\n",
      "[Train] Step: 4300, loss: 1.22212, acc: 0.55000\n",
      "[Train] Step: 4400, loss: 1.07222, acc: 0.70000\n",
      "[Train] Step: 4500, loss: 0.90249, acc: 0.75000\n",
      "[Train] Step: 4600, loss: 0.75470, acc: 0.75000\n",
      "[Train] Step: 4700, loss: 0.68486, acc: 0.85000\n",
      "[Train] Step: 4800, loss: 0.59845, acc: 0.85000\n",
      "[Train] Step: 4900, loss: 0.69298, acc: 0.85000\n",
      "[Train] Step: 5000, loss: 0.65843, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 5000, acc: 0.66100\n",
      "[Train] Step: 5100, loss: 0.79285, acc: 0.75000\n",
      "[Train] Step: 5200, loss: 1.21270, acc: 0.70000\n",
      "[Train] Step: 5300, loss: 0.77003, acc: 0.60000\n",
      "[Train] Step: 5400, loss: 0.78904, acc: 0.75000\n",
      "[Train] Step: 5500, loss: 0.55990, acc: 0.75000\n",
      "[Train] Step: 5600, loss: 0.70636, acc: 0.75000\n",
      "[Train] Step: 5700, loss: 0.65117, acc: 0.85000\n",
      "[Train] Step: 5800, loss: 0.97541, acc: 0.60000\n",
      "[Train] Step: 5900, loss: 0.79971, acc: 0.70000\n",
      "[Train] Step: 6000, loss: 0.90173, acc: 0.70000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 6000, acc: 0.69750\n",
      "[Train] Step: 6100, loss: 0.67914, acc: 0.65000\n",
      "[Train] Step: 6200, loss: 0.75539, acc: 0.75000\n",
      "[Train] Step: 6300, loss: 0.61879, acc: 0.70000\n",
      "[Train] Step: 6400, loss: 0.90508, acc: 0.75000\n",
      "[Train] Step: 6500, loss: 1.21472, acc: 0.65000\n",
      "[Train] Step: 6600, loss: 0.88779, acc: 0.60000\n",
      "[Train] Step: 6700, loss: 0.97661, acc: 0.70000\n",
      "[Train] Step: 6800, loss: 1.18768, acc: 0.70000\n",
      "[Train] Step: 6900, loss: 1.35544, acc: 0.55000\n",
      "[Train] Step: 7000, loss: 1.37221, acc: 0.50000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 7000, acc: 0.70050\n",
      "[Train] Step: 7100, loss: 0.55941, acc: 0.80000\n",
      "[Train] Step: 7200, loss: 0.53515, acc: 0.85000\n",
      "[Train] Step: 7300, loss: 0.64008, acc: 0.85000\n",
      "[Train] Step: 7400, loss: 0.58862, acc: 0.75000\n",
      "[Train] Step: 7500, loss: 0.59837, acc: 0.80000\n",
      "[Train] Step: 7600, loss: 0.87669, acc: 0.65000\n",
      "[Train] Step: 7700, loss: 0.80066, acc: 0.85000\n",
      "[Train] Step: 7800, loss: 1.08314, acc: 0.60000\n",
      "[Train] Step: 7900, loss: 0.45644, acc: 0.80000\n",
      "[Train] Step: 8000, loss: 0.36566, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 8000, acc: 0.72350\n",
      "[Train] Step: 8100, loss: 1.14377, acc: 0.65000\n",
      "[Train] Step: 8200, loss: 0.29513, acc: 0.90000\n",
      "[Train] Step: 8300, loss: 1.25256, acc: 0.50000\n",
      "[Train] Step: 8400, loss: 0.46104, acc: 0.85000\n",
      "[Train] Step: 8500, loss: 0.88658, acc: 0.80000\n",
      "[Train] Step: 8600, loss: 0.73901, acc: 0.75000\n",
      "[Train] Step: 8700, loss: 0.74383, acc: 0.70000\n",
      "[Train] Step: 8800, loss: 0.56661, acc: 0.75000\n",
      "[Train] Step: 8900, loss: 1.33479, acc: 0.55000\n",
      "[Train] Step: 9000, loss: 0.95887, acc: 0.70000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 9000, acc: 0.72500\n",
      "[Train] Step: 9100, loss: 0.58867, acc: 0.85000\n",
      "[Train] Step: 9200, loss: 1.37311, acc: 0.50000\n",
      "[Train] Step: 9300, loss: 1.25424, acc: 0.50000\n",
      "[Train] Step: 9400, loss: 0.61368, acc: 0.85000\n",
      "[Train] Step: 9500, loss: 0.57369, acc: 0.70000\n",
      "[Train] Step: 9600, loss: 0.39048, acc: 0.80000\n",
      "[Train] Step: 9700, loss: 0.55758, acc: 0.85000\n",
      "[Train] Step: 9800, loss: 0.34067, acc: 0.90000\n",
      "[Train] Step: 9900, loss: 0.78161, acc: 0.70000\n",
      "[Train] Step: 10000, loss: 0.70174, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 10000, acc: 0.72650\n",
      "[Train] Step: 10100, loss: 0.59721, acc: 0.80000\n",
      "[Train] Step: 10200, loss: 0.54607, acc: 0.70000\n",
      "[Train] Step: 10300, loss: 0.83440, acc: 0.70000\n",
      "[Train] Step: 10400, loss: 0.77151, acc: 0.75000\n",
      "[Train] Step: 10500, loss: 0.47226, acc: 0.85000\n",
      "[Train] Step: 10600, loss: 0.61849, acc: 0.75000\n",
      "[Train] Step: 10700, loss: 0.49110, acc: 0.85000\n",
      "[Train] Step: 10800, loss: 0.94520, acc: 0.55000\n",
      "[Train] Step: 10900, loss: 0.42485, acc: 0.85000\n",
      "[Train] Step: 11000, loss: 0.72794, acc: 0.75000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 11000, acc: 0.73000\n",
      "[Train] Step: 11100, loss: 0.36643, acc: 0.90000\n",
      "[Train] Step: 11200, loss: 0.63820, acc: 0.85000\n",
      "[Train] Step: 11300, loss: 0.72502, acc: 0.70000\n",
      "[Train] Step: 11400, loss: 0.44684, acc: 0.85000\n",
      "[Train] Step: 11500, loss: 0.43343, acc: 0.85000\n",
      "[Train] Step: 11600, loss: 0.60887, acc: 0.85000\n",
      "[Train] Step: 11700, loss: 0.58242, acc: 0.80000\n",
      "[Train] Step: 11800, loss: 0.40668, acc: 0.85000\n",
      "[Train] Step: 11900, loss: 0.35474, acc: 0.90000\n",
      "[Train] Step: 12000, loss: 0.30883, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 12000, acc: 0.71450\n",
      "[Train] Step: 12100, loss: 0.71209, acc: 0.80000\n",
      "[Train] Step: 12200, loss: 0.33911, acc: 0.90000\n",
      "[Train] Step: 12300, loss: 0.47005, acc: 0.85000\n",
      "[Train] Step: 12400, loss: 0.84430, acc: 0.70000\n",
      "[Train] Step: 12500, loss: 0.58772, acc: 0.85000\n",
      "[Train] Step: 12600, loss: 0.51216, acc: 0.85000\n",
      "[Train] Step: 12700, loss: 0.90174, acc: 0.80000\n",
      "[Train] Step: 12800, loss: 0.77589, acc: 0.70000\n",
      "[Train] Step: 12900, loss: 0.67784, acc: 0.65000\n",
      "[Train] Step: 13000, loss: 0.80040, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 13000, acc: 0.74050\n",
      "[Train] Step: 13100, loss: 0.71643, acc: 0.70000\n",
      "[Train] Step: 13200, loss: 0.35292, acc: 0.90000\n",
      "[Train] Step: 13300, loss: 0.65749, acc: 0.75000\n",
      "[Train] Step: 13400, loss: 0.64412, acc: 0.80000\n",
      "[Train] Step: 13500, loss: 0.55493, acc: 0.75000\n",
      "[Train] Step: 13600, loss: 1.29921, acc: 0.65000\n",
      "[Train] Step: 13700, loss: 0.40321, acc: 0.85000\n",
      "[Train] Step: 13800, loss: 0.72012, acc: 0.70000\n",
      "[Train] Step: 13900, loss: 0.18043, acc: 0.95000\n",
      "[Train] Step: 14000, loss: 0.40639, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 14000, acc: 0.74400\n",
      "[Train] Step: 14100, loss: 0.54243, acc: 0.75000\n",
      "[Train] Step: 14200, loss: 0.56220, acc: 0.80000\n",
      "[Train] Step: 14300, loss: 0.47980, acc: 0.75000\n",
      "[Train] Step: 14400, loss: 0.68334, acc: 0.75000\n",
      "[Train] Step: 14500, loss: 0.39176, acc: 0.85000\n",
      "[Train] Step: 14600, loss: 0.43574, acc: 0.90000\n",
      "[Train] Step: 14700, loss: 0.77938, acc: 0.75000\n",
      "[Train] Step: 14800, loss: 1.00330, acc: 0.60000\n",
      "[Train] Step: 14900, loss: 0.97727, acc: 0.60000\n",
      "[Train] Step: 15000, loss: 0.58168, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 15000, acc: 0.75350\n",
      "[Train] Step: 15100, loss: 0.70315, acc: 0.70000\n",
      "[Train] Step: 15200, loss: 0.89074, acc: 0.65000\n",
      "[Train] Step: 15300, loss: 0.45653, acc: 0.80000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 15400, loss: 0.36394, acc: 0.90000\n",
      "[Train] Step: 15500, loss: 0.38761, acc: 0.85000\n",
      "[Train] Step: 15600, loss: 0.71818, acc: 0.75000\n",
      "[Train] Step: 15700, loss: 1.29245, acc: 0.60000\n",
      "[Train] Step: 15800, loss: 0.75236, acc: 0.75000\n",
      "[Train] Step: 15900, loss: 0.84840, acc: 0.55000\n",
      "[Train] Step: 16000, loss: 0.41771, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 16000, acc: 0.74000\n",
      "[Train] Step: 16100, loss: 0.30598, acc: 0.90000\n",
      "[Train] Step: 16200, loss: 0.59433, acc: 0.75000\n",
      "[Train] Step: 16300, loss: 0.84176, acc: 0.65000\n",
      "[Train] Step: 16400, loss: 0.56957, acc: 0.75000\n",
      "[Train] Step: 16500, loss: 0.58433, acc: 0.75000\n",
      "[Train] Step: 16600, loss: 1.06285, acc: 0.65000\n",
      "[Train] Step: 16700, loss: 0.66252, acc: 0.75000\n",
      "[Train] Step: 16800, loss: 0.29141, acc: 1.00000\n",
      "[Train] Step: 16900, loss: 0.30731, acc: 0.85000\n",
      "[Train] Step: 17000, loss: 0.72640, acc: 0.75000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 17000, acc: 0.73450\n",
      "[Train] Step: 17100, loss: 0.37430, acc: 0.90000\n",
      "[Train] Step: 17200, loss: 0.78730, acc: 0.80000\n",
      "[Train] Step: 17300, loss: 0.81208, acc: 0.65000\n",
      "[Train] Step: 17400, loss: 0.91404, acc: 0.75000\n",
      "[Train] Step: 17500, loss: 0.73352, acc: 0.65000\n",
      "[Train] Step: 17600, loss: 0.80276, acc: 0.80000\n",
      "[Train] Step: 17700, loss: 0.53366, acc: 0.90000\n",
      "[Train] Step: 17800, loss: 0.49888, acc: 0.85000\n",
      "[Train] Step: 17900, loss: 0.75852, acc: 0.70000\n",
      "[Train] Step: 18000, loss: 0.33955, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 18000, acc: 0.75750\n",
      "[Train] Step: 18100, loss: 0.58195, acc: 0.80000\n",
      "[Train] Step: 18200, loss: 0.62476, acc: 0.85000\n",
      "[Train] Step: 18300, loss: 0.71563, acc: 0.70000\n",
      "[Train] Step: 18400, loss: 0.23467, acc: 0.95000\n",
      "[Train] Step: 18500, loss: 1.24328, acc: 0.60000\n",
      "[Train] Step: 18600, loss: 0.91178, acc: 0.75000\n",
      "[Train] Step: 18700, loss: 0.97086, acc: 0.80000\n",
      "[Train] Step: 18800, loss: 0.35959, acc: 0.85000\n",
      "[Train] Step: 18900, loss: 0.40873, acc: 0.85000\n",
      "[Train] Step: 19000, loss: 0.24438, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 19000, acc: 0.75200\n",
      "[Train] Step: 19100, loss: 0.48237, acc: 0.85000\n",
      "[Train] Step: 19200, loss: 0.37142, acc: 0.85000\n",
      "[Train] Step: 19300, loss: 0.68620, acc: 0.80000\n",
      "[Train] Step: 19400, loss: 0.39170, acc: 0.90000\n",
      "[Train] Step: 19500, loss: 0.31850, acc: 0.85000\n",
      "[Train] Step: 19600, loss: 0.49211, acc: 0.85000\n",
      "[Train] Step: 19700, loss: 0.96722, acc: 0.80000\n",
      "[Train] Step: 19800, loss: 0.74296, acc: 0.65000\n",
      "[Train] Step: 19900, loss: 0.47417, acc: 0.85000\n",
      "[Train] Step: 20000, loss: 0.39956, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 20000, acc: 0.74400\n",
      "[Train] Step: 20100, loss: 0.16330, acc: 0.95000\n",
      "[Train] Step: 20200, loss: 0.29610, acc: 0.90000\n",
      "[Train] Step: 20300, loss: 0.44694, acc: 0.85000\n",
      "[Train] Step: 20400, loss: 0.64732, acc: 0.80000\n",
      "[Train] Step: 20500, loss: 0.31013, acc: 0.90000\n",
      "[Train] Step: 20600, loss: 0.46553, acc: 0.85000\n",
      "[Train] Step: 20700, loss: 0.26859, acc: 0.85000\n",
      "[Train] Step: 20800, loss: 0.78958, acc: 0.75000\n",
      "[Train] Step: 20900, loss: 0.51548, acc: 0.85000\n",
      "[Train] Step: 21000, loss: 0.49579, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 21000, acc: 0.74900\n",
      "[Train] Step: 21100, loss: 0.37013, acc: 0.85000\n",
      "[Train] Step: 21200, loss: 0.77028, acc: 0.75000\n",
      "[Train] Step: 21300, loss: 0.68369, acc: 0.75000\n",
      "[Train] Step: 21400, loss: 0.58244, acc: 0.75000\n",
      "[Train] Step: 21500, loss: 0.42751, acc: 0.90000\n",
      "[Train] Step: 21600, loss: 0.50190, acc: 0.80000\n",
      "[Train] Step: 21700, loss: 0.46304, acc: 0.80000\n",
      "[Train] Step: 21800, loss: 0.64479, acc: 0.85000\n",
      "[Train] Step: 21900, loss: 1.11160, acc: 0.65000\n",
      "[Train] Step: 22000, loss: 0.65352, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 22000, acc: 0.74550\n",
      "[Train] Step: 22100, loss: 0.75998, acc: 0.65000\n",
      "[Train] Step: 22200, loss: 0.42569, acc: 0.80000\n",
      "[Train] Step: 22300, loss: 0.36332, acc: 0.85000\n",
      "[Train] Step: 22400, loss: 0.63797, acc: 0.75000\n",
      "[Train] Step: 22500, loss: 0.30605, acc: 0.90000\n",
      "[Train] Step: 22600, loss: 0.38224, acc: 0.85000\n",
      "[Train] Step: 22700, loss: 0.63423, acc: 0.85000\n",
      "[Train] Step: 22800, loss: 0.21847, acc: 0.95000\n",
      "[Train] Step: 22900, loss: 0.45126, acc: 0.85000\n",
      "[Train] Step: 23000, loss: 0.41526, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 23000, acc: 0.75250\n",
      "[Train] Step: 23100, loss: 0.58636, acc: 0.70000\n",
      "[Train] Step: 23200, loss: 0.35199, acc: 0.80000\n",
      "[Train] Step: 23300, loss: 0.27476, acc: 0.85000\n",
      "[Train] Step: 23400, loss: 0.60140, acc: 0.90000\n",
      "[Train] Step: 23500, loss: 0.73601, acc: 0.65000\n",
      "[Train] Step: 23600, loss: 0.29448, acc: 0.90000\n",
      "[Train] Step: 23700, loss: 0.72450, acc: 0.70000\n",
      "[Train] Step: 23800, loss: 0.70877, acc: 0.75000\n",
      "[Train] Step: 23900, loss: 0.86042, acc: 0.70000\n",
      "[Train] Step: 24000, loss: 0.21875, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 24000, acc: 0.74200\n",
      "[Train] Step: 24100, loss: 0.48344, acc: 0.80000\n",
      "[Train] Step: 24200, loss: 0.37183, acc: 0.90000\n",
      "[Train] Step: 24300, loss: 0.74190, acc: 0.80000\n",
      "[Train] Step: 24400, loss: 0.65199, acc: 0.75000\n",
      "[Train] Step: 24500, loss: 0.73402, acc: 0.70000\n",
      "[Train] Step: 24600, loss: 0.35937, acc: 0.85000\n",
      "[Train] Step: 24700, loss: 0.65645, acc: 0.75000\n",
      "[Train] Step: 24800, loss: 0.57730, acc: 0.75000\n",
      "[Train] Step: 24900, loss: 0.22347, acc: 0.95000\n",
      "[Train] Step: 25000, loss: 0.77975, acc: 0.75000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 25000, acc: 0.74300\n",
      "[Train] Step: 25100, loss: 0.38927, acc: 0.90000\n",
      "[Train] Step: 25200, loss: 0.37938, acc: 0.85000\n",
      "[Train] Step: 25300, loss: 0.34360, acc: 0.90000\n",
      "[Train] Step: 25400, loss: 0.51310, acc: 0.70000\n",
      "[Train] Step: 25500, loss: 0.39633, acc: 0.80000\n",
      "[Train] Step: 25600, loss: 0.22633, acc: 0.95000\n",
      "[Train] Step: 25700, loss: 0.44625, acc: 0.80000\n",
      "[Train] Step: 25800, loss: 0.70060, acc: 0.80000\n",
      "[Train] Step: 25900, loss: 1.05847, acc: 0.65000\n",
      "[Train] Step: 26000, loss: 0.18617, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 26000, acc: 0.73300\n",
      "[Train] Step: 26100, loss: 0.74302, acc: 0.75000\n",
      "[Train] Step: 26200, loss: 0.34229, acc: 0.85000\n",
      "[Train] Step: 26300, loss: 0.34197, acc: 0.85000\n",
      "[Train] Step: 26400, loss: 0.88518, acc: 0.75000\n",
      "[Train] Step: 26500, loss: 0.35451, acc: 0.90000\n",
      "[Train] Step: 26600, loss: 0.45225, acc: 0.90000\n",
      "[Train] Step: 26700, loss: 0.60134, acc: 0.80000\n",
      "[Train] Step: 26800, loss: 0.44159, acc: 0.90000\n",
      "[Train] Step: 26900, loss: 0.35354, acc: 0.80000\n",
      "[Train] Step: 27000, loss: 0.35778, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 27000, acc: 0.74900\n",
      "[Train] Step: 27100, loss: 0.21223, acc: 0.90000\n",
      "[Train] Step: 27200, loss: 0.41011, acc: 0.90000\n",
      "[Train] Step: 27300, loss: 0.80027, acc: 0.80000\n",
      "[Train] Step: 27400, loss: 0.65370, acc: 0.70000\n",
      "[Train] Step: 27500, loss: 0.43790, acc: 0.85000\n",
      "[Train] Step: 27600, loss: 0.26437, acc: 0.85000\n",
      "[Train] Step: 27700, loss: 0.30530, acc: 0.90000\n",
      "[Train] Step: 27800, loss: 0.47449, acc: 0.90000\n",
      "[Train] Step: 27900, loss: 0.53338, acc: 0.85000\n",
      "[Train] Step: 28000, loss: 0.44314, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 28000, acc: 0.75400\n",
      "[Train] Step: 28100, loss: 0.21360, acc: 0.95000\n",
      "[Train] Step: 28200, loss: 0.86687, acc: 0.70000\n",
      "[Train] Step: 28300, loss: 0.57657, acc: 0.70000\n",
      "[Train] Step: 28400, loss: 0.53943, acc: 0.80000\n",
      "[Train] Step: 28500, loss: 0.20749, acc: 0.95000\n",
      "[Train] Step: 28600, loss: 0.26697, acc: 0.90000\n",
      "[Train] Step: 28700, loss: 0.51735, acc: 0.85000\n",
      "[Train] Step: 28800, loss: 0.18637, acc: 0.90000\n",
      "[Train] Step: 28900, loss: 0.46383, acc: 0.75000\n",
      "[Train] Step: 29000, loss: 0.41823, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 29000, acc: 0.74500\n",
      "[Train] Step: 29100, loss: 0.68882, acc: 0.70000\n",
      "[Train] Step: 29200, loss: 0.08126, acc: 1.00000\n",
      "[Train] Step: 29300, loss: 0.35413, acc: 0.90000\n",
      "[Train] Step: 29400, loss: 0.50393, acc: 0.80000\n",
      "[Train] Step: 29500, loss: 0.58657, acc: 0.80000\n",
      "[Train] Step: 29600, loss: 0.59658, acc: 0.65000\n",
      "[Train] Step: 29700, loss: 0.32635, acc: 0.90000\n",
      "[Train] Step: 29800, loss: 0.72948, acc: 0.80000\n",
      "[Train] Step: 29900, loss: 0.39965, acc: 0.85000\n",
      "[Train] Step: 30000, loss: 0.47805, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 30000, acc: 0.74400\n",
      "[Train] Step: 30100, loss: 0.19083, acc: 0.95000\n",
      "[Train] Step: 30200, loss: 0.34920, acc: 0.85000\n",
      "[Train] Step: 30300, loss: 0.39754, acc: 0.85000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 30400, loss: 0.55609, acc: 0.85000\n",
      "[Train] Step: 30500, loss: 1.28615, acc: 0.75000\n",
      "[Train] Step: 30600, loss: 0.54507, acc: 0.80000\n",
      "[Train] Step: 30700, loss: 0.88949, acc: 0.70000\n",
      "[Train] Step: 30800, loss: 0.30266, acc: 0.90000\n",
      "[Train] Step: 30900, loss: 0.46026, acc: 0.80000\n",
      "[Train] Step: 31000, loss: 0.55032, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 31000, acc: 0.74750\n",
      "[Train] Step: 31100, loss: 0.63243, acc: 0.80000\n",
      "[Train] Step: 31200, loss: 0.17114, acc: 1.00000\n",
      "[Train] Step: 31300, loss: 0.44045, acc: 0.85000\n",
      "[Train] Step: 31400, loss: 0.49304, acc: 0.75000\n",
      "[Train] Step: 31500, loss: 0.68125, acc: 0.75000\n",
      "[Train] Step: 31600, loss: 1.17788, acc: 0.70000\n",
      "[Train] Step: 31700, loss: 0.21684, acc: 0.95000\n",
      "[Train] Step: 31800, loss: 0.46517, acc: 0.85000\n",
      "[Train] Step: 31900, loss: 0.18906, acc: 0.90000\n",
      "[Train] Step: 32000, loss: 0.65864, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 32000, acc: 0.73650\n",
      "[Train] Step: 32100, loss: 0.48578, acc: 0.75000\n",
      "[Train] Step: 32200, loss: 0.66138, acc: 0.80000\n",
      "[Train] Step: 32300, loss: 0.65803, acc: 0.70000\n",
      "[Train] Step: 32400, loss: 0.93569, acc: 0.65000\n",
      "[Train] Step: 32500, loss: 0.38543, acc: 0.85000\n",
      "[Train] Step: 32600, loss: 0.32396, acc: 0.90000\n",
      "[Train] Step: 32700, loss: 0.36826, acc: 0.90000\n",
      "[Train] Step: 32800, loss: 0.37421, acc: 0.80000\n",
      "[Train] Step: 32900, loss: 0.40166, acc: 0.80000\n",
      "[Train] Step: 33000, loss: 0.23634, acc: 1.00000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 33000, acc: 0.74050\n",
      "[Train] Step: 33100, loss: 0.43402, acc: 0.85000\n",
      "[Train] Step: 33200, loss: 0.72696, acc: 0.80000\n",
      "[Train] Step: 33300, loss: 0.51231, acc: 0.85000\n",
      "[Train] Step: 33400, loss: 0.35520, acc: 0.90000\n",
      "[Train] Step: 33500, loss: 0.95187, acc: 0.70000\n",
      "[Train] Step: 33600, loss: 0.25466, acc: 0.90000\n",
      "[Train] Step: 33700, loss: 0.45816, acc: 0.85000\n",
      "[Train] Step: 33800, loss: 0.37134, acc: 0.90000\n",
      "[Train] Step: 33900, loss: 0.36704, acc: 0.85000\n",
      "[Train] Step: 34000, loss: 0.43799, acc: 0.75000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 34000, acc: 0.74000\n",
      "[Train] Step: 34100, loss: 0.55399, acc: 0.70000\n",
      "[Train] Step: 34200, loss: 0.15208, acc: 1.00000\n",
      "[Train] Step: 34300, loss: 0.11791, acc: 0.95000\n",
      "[Train] Step: 34400, loss: 0.71851, acc: 0.80000\n",
      "[Train] Step: 34500, loss: 0.53120, acc: 0.85000\n",
      "[Train] Step: 34600, loss: 0.44785, acc: 0.85000\n",
      "[Train] Step: 34700, loss: 0.92803, acc: 0.70000\n",
      "[Train] Step: 34800, loss: 0.73140, acc: 0.85000\n",
      "[Train] Step: 34900, loss: 0.51150, acc: 0.90000\n",
      "[Train] Step: 35000, loss: 0.38506, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 35000, acc: 0.73800\n",
      "[Train] Step: 35100, loss: 0.17407, acc: 0.90000\n",
      "[Train] Step: 35200, loss: 0.60515, acc: 0.80000\n",
      "[Train] Step: 35300, loss: 0.26272, acc: 0.85000\n",
      "[Train] Step: 35400, loss: 0.37312, acc: 0.85000\n",
      "[Train] Step: 35500, loss: 0.34048, acc: 0.80000\n",
      "[Train] Step: 35600, loss: 0.38588, acc: 0.85000\n",
      "[Train] Step: 35700, loss: 0.32076, acc: 0.90000\n",
      "[Train] Step: 35800, loss: 0.66583, acc: 0.65000\n",
      "[Train] Step: 35900, loss: 0.26844, acc: 0.90000\n",
      "[Train] Step: 36000, loss: 0.61032, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 36000, acc: 0.75300\n",
      "[Train] Step: 36100, loss: 0.24569, acc: 0.95000\n",
      "[Train] Step: 36200, loss: 0.81846, acc: 0.75000\n",
      "[Train] Step: 36300, loss: 0.40853, acc: 0.85000\n",
      "[Train] Step: 36400, loss: 0.33084, acc: 0.85000\n",
      "[Train] Step: 36500, loss: 0.60159, acc: 0.80000\n",
      "[Train] Step: 36600, loss: 0.28185, acc: 0.90000\n",
      "[Train] Step: 36700, loss: 0.21508, acc: 0.95000\n",
      "[Train] Step: 36800, loss: 0.41956, acc: 0.80000\n",
      "[Train] Step: 36900, loss: 0.10108, acc: 1.00000\n",
      "[Train] Step: 37000, loss: 0.21585, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 37000, acc: 0.73700\n",
      "[Train] Step: 37100, loss: 0.54071, acc: 0.75000\n",
      "[Train] Step: 37200, loss: 0.34394, acc: 0.85000\n",
      "[Train] Step: 37300, loss: 0.44951, acc: 0.85000\n",
      "[Train] Step: 37400, loss: 0.41223, acc: 0.80000\n",
      "[Train] Step: 37500, loss: 0.78994, acc: 0.70000\n",
      "[Train] Step: 37600, loss: 0.50156, acc: 0.85000\n",
      "[Train] Step: 37700, loss: 0.80485, acc: 0.75000\n",
      "[Train] Step: 37800, loss: 0.21692, acc: 0.90000\n",
      "[Train] Step: 37900, loss: 0.41028, acc: 0.85000\n",
      "[Train] Step: 38000, loss: 0.16297, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 38000, acc: 0.74000\n",
      "[Train] Step: 38100, loss: 0.23163, acc: 0.90000\n",
      "[Train] Step: 38200, loss: 0.49698, acc: 0.85000\n",
      "[Train] Step: 38300, loss: 0.38952, acc: 0.90000\n",
      "[Train] Step: 38400, loss: 0.28128, acc: 0.95000\n",
      "[Train] Step: 38500, loss: 0.24633, acc: 0.95000\n",
      "[Train] Step: 38600, loss: 0.34319, acc: 0.90000\n",
      "[Train] Step: 38700, loss: 0.82686, acc: 0.75000\n",
      "[Train] Step: 38800, loss: 0.13814, acc: 0.95000\n",
      "[Train] Step: 38900, loss: 0.56548, acc: 0.75000\n",
      "[Train] Step: 39000, loss: 0.61260, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 39000, acc: 0.74350\n",
      "[Train] Step: 39100, loss: 0.42404, acc: 0.80000\n",
      "[Train] Step: 39200, loss: 0.52042, acc: 0.80000\n",
      "[Train] Step: 39300, loss: 0.57734, acc: 0.80000\n",
      "[Train] Step: 39400, loss: 0.31612, acc: 0.85000\n",
      "[Train] Step: 39500, loss: 0.03846, acc: 1.00000\n",
      "[Train] Step: 39600, loss: 0.55050, acc: 0.85000\n",
      "[Train] Step: 39700, loss: 0.24874, acc: 0.95000\n",
      "[Train] Step: 39800, loss: 0.35043, acc: 0.90000\n",
      "[Train] Step: 39900, loss: 0.59075, acc: 0.75000\n",
      "[Train] Step: 40000, loss: 0.50641, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 40000, acc: 0.75450\n",
      "[Train] Step: 40100, loss: 0.39766, acc: 0.85000\n",
      "[Train] Step: 40200, loss: 0.18731, acc: 0.90000\n",
      "[Train] Step: 40300, loss: 0.15169, acc: 0.95000\n",
      "[Train] Step: 40400, loss: 0.31867, acc: 0.85000\n",
      "[Train] Step: 40500, loss: 0.14015, acc: 0.95000\n",
      "[Train] Step: 40600, loss: 0.34809, acc: 0.85000\n",
      "[Train] Step: 40700, loss: 0.31130, acc: 0.85000\n",
      "[Train] Step: 40800, loss: 0.25924, acc: 0.90000\n",
      "[Train] Step: 40900, loss: 0.30795, acc: 0.80000\n",
      "[Train] Step: 41000, loss: 0.66579, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 41000, acc: 0.74800\n",
      "[Train] Step: 41100, loss: 0.50264, acc: 0.80000\n",
      "[Train] Step: 41200, loss: 0.48563, acc: 0.90000\n",
      "[Train] Step: 41300, loss: 0.34256, acc: 0.85000\n",
      "[Train] Step: 41400, loss: 0.19953, acc: 0.95000\n",
      "[Train] Step: 41500, loss: 0.22264, acc: 0.90000\n",
      "[Train] Step: 41600, loss: 0.27874, acc: 0.95000\n",
      "[Train] Step: 41700, loss: 0.85494, acc: 0.75000\n",
      "[Train] Step: 41800, loss: 0.62134, acc: 0.75000\n",
      "[Train] Step: 41900, loss: 0.64175, acc: 0.75000\n",
      "[Train] Step: 42000, loss: 0.50515, acc: 0.75000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 42000, acc: 0.73600\n",
      "[Train] Step: 42100, loss: 0.56577, acc: 0.80000\n",
      "[Train] Step: 42200, loss: 0.10411, acc: 1.00000\n",
      "[Train] Step: 42300, loss: 0.27163, acc: 0.90000\n",
      "[Train] Step: 42400, loss: 0.59979, acc: 0.85000\n",
      "[Train] Step: 42500, loss: 0.59685, acc: 0.90000\n",
      "[Train] Step: 42600, loss: 0.45916, acc: 0.85000\n",
      "[Train] Step: 42700, loss: 0.45675, acc: 0.85000\n",
      "[Train] Step: 42800, loss: 0.61215, acc: 0.80000\n",
      "[Train] Step: 42900, loss: 0.19007, acc: 0.95000\n",
      "[Train] Step: 43000, loss: 0.43657, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 43000, acc: 0.75300\n",
      "[Train] Step: 43100, loss: 0.20523, acc: 0.95000\n",
      "[Train] Step: 43200, loss: 1.00642, acc: 0.70000\n",
      "[Train] Step: 43300, loss: 0.34829, acc: 0.90000\n",
      "[Train] Step: 43400, loss: 0.32584, acc: 0.90000\n",
      "[Train] Step: 43500, loss: 0.64222, acc: 0.85000\n",
      "[Train] Step: 43600, loss: 0.37563, acc: 0.90000\n",
      "[Train] Step: 43700, loss: 0.57004, acc: 0.80000\n",
      "[Train] Step: 43800, loss: 0.18182, acc: 0.90000\n",
      "[Train] Step: 43900, loss: 0.59962, acc: 0.75000\n",
      "[Train] Step: 44000, loss: 0.36606, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 44000, acc: 0.73650\n",
      "[Train] Step: 44100, loss: 0.21993, acc: 0.95000\n",
      "[Train] Step: 44200, loss: 0.25706, acc: 0.95000\n",
      "[Train] Step: 44300, loss: 0.34654, acc: 0.80000\n",
      "[Train] Step: 44400, loss: 0.38505, acc: 0.90000\n",
      "[Train] Step: 44500, loss: 0.66606, acc: 0.80000\n",
      "[Train] Step: 44600, loss: 0.20984, acc: 0.90000\n",
      "[Train] Step: 44700, loss: 0.30401, acc: 0.90000\n",
      "[Train] Step: 44800, loss: 0.30724, acc: 0.90000\n",
      "[Train] Step: 44900, loss: 0.59503, acc: 0.75000\n",
      "[Train] Step: 45000, loss: 0.38868, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 45000, acc: 0.74600\n",
      "[Train] Step: 45100, loss: 0.17431, acc: 0.95000\n",
      "[Train] Step: 45200, loss: 0.35319, acc: 0.90000\n",
      "[Train] Step: 45300, loss: 1.18615, acc: 0.70000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 45400, loss: 0.49654, acc: 0.85000\n",
      "[Train] Step: 45500, loss: 0.21985, acc: 0.95000\n",
      "[Train] Step: 45600, loss: 0.43808, acc: 0.75000\n",
      "[Train] Step: 45700, loss: 0.38437, acc: 0.90000\n",
      "[Train] Step: 45800, loss: 0.24140, acc: 0.90000\n",
      "[Train] Step: 45900, loss: 0.63223, acc: 0.70000\n",
      "[Train] Step: 46000, loss: 0.45916, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 46000, acc: 0.73700\n",
      "[Train] Step: 46100, loss: 0.53786, acc: 0.85000\n",
      "[Train] Step: 46200, loss: 0.67005, acc: 0.85000\n",
      "[Train] Step: 46300, loss: 0.34858, acc: 0.95000\n",
      "[Train] Step: 46400, loss: 0.31351, acc: 0.95000\n",
      "[Train] Step: 46500, loss: 0.08023, acc: 1.00000\n",
      "[Train] Step: 46600, loss: 0.53299, acc: 0.85000\n",
      "[Train] Step: 46700, loss: 0.34264, acc: 0.85000\n",
      "[Train] Step: 46800, loss: 0.23806, acc: 0.90000\n",
      "[Train] Step: 46900, loss: 0.29038, acc: 0.85000\n",
      "[Train] Step: 47000, loss: 0.26991, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 47000, acc: 0.74900\n",
      "[Train] Step: 47100, loss: 0.28844, acc: 0.85000\n",
      "[Train] Step: 47200, loss: 0.91769, acc: 0.80000\n",
      "[Train] Step: 47300, loss: 0.34262, acc: 0.95000\n",
      "[Train] Step: 47400, loss: 0.40768, acc: 0.80000\n",
      "[Train] Step: 47500, loss: 0.74587, acc: 0.75000\n",
      "[Train] Step: 47600, loss: 0.31860, acc: 0.90000\n",
      "[Train] Step: 47700, loss: 0.36211, acc: 0.90000\n",
      "[Train] Step: 47800, loss: 0.26860, acc: 0.90000\n",
      "[Train] Step: 47900, loss: 0.65048, acc: 0.65000\n",
      "[Train] Step: 48000, loss: 0.33074, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 48000, acc: 0.75050\n",
      "[Train] Step: 48100, loss: 0.18036, acc: 0.95000\n",
      "[Train] Step: 48200, loss: 0.37634, acc: 0.90000\n",
      "[Train] Step: 48300, loss: 0.12090, acc: 1.00000\n",
      "[Train] Step: 48400, loss: 0.50006, acc: 0.90000\n",
      "[Train] Step: 48500, loss: 0.47279, acc: 0.85000\n",
      "[Train] Step: 48600, loss: 0.29367, acc: 0.90000\n",
      "[Train] Step: 48700, loss: 0.45412, acc: 0.85000\n",
      "[Train] Step: 48800, loss: 0.28022, acc: 0.85000\n",
      "[Train] Step: 48900, loss: 0.82997, acc: 0.75000\n",
      "[Train] Step: 49000, loss: 0.59593, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 49000, acc: 0.73150\n",
      "[Train] Step: 49100, loss: 0.37384, acc: 0.90000\n",
      "[Train] Step: 49200, loss: 0.33615, acc: 0.85000\n",
      "[Train] Step: 49300, loss: 0.45353, acc: 0.85000\n",
      "[Train] Step: 49400, loss: 0.25220, acc: 0.90000\n",
      "[Train] Step: 49500, loss: 0.20052, acc: 0.95000\n",
      "[Train] Step: 49600, loss: 0.07966, acc: 1.00000\n",
      "[Train] Step: 49700, loss: 0.97868, acc: 0.85000\n",
      "[Train] Step: 49800, loss: 0.35507, acc: 0.90000\n",
      "[Train] Step: 49900, loss: 0.63358, acc: 0.75000\n",
      "[Train] Step: 50000, loss: 0.35251, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 50000, acc: 0.73200\n",
      "[Train] Step: 50100, loss: 0.33092, acc: 0.80000\n",
      "[Train] Step: 50200, loss: 0.20212, acc: 0.95000\n",
      "[Train] Step: 50300, loss: 0.07408, acc: 1.00000\n",
      "[Train] Step: 50400, loss: 0.49617, acc: 0.80000\n",
      "[Train] Step: 50500, loss: 0.32550, acc: 0.85000\n",
      "[Train] Step: 50600, loss: 0.30609, acc: 0.90000\n",
      "[Train] Step: 50700, loss: 0.21281, acc: 0.95000\n",
      "[Train] Step: 50800, loss: 0.27962, acc: 0.90000\n",
      "[Train] Step: 50900, loss: 0.22214, acc: 0.95000\n",
      "[Train] Step: 51000, loss: 0.31864, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 51000, acc: 0.72750\n",
      "[Train] Step: 51100, loss: 0.13373, acc: 0.95000\n",
      "[Train] Step: 51200, loss: 0.16988, acc: 0.95000\n",
      "[Train] Step: 51300, loss: 0.37174, acc: 0.85000\n",
      "[Train] Step: 51400, loss: 0.31508, acc: 0.85000\n",
      "[Train] Step: 51500, loss: 0.36057, acc: 0.85000\n",
      "[Train] Step: 51600, loss: 0.53217, acc: 0.75000\n",
      "[Train] Step: 51700, loss: 0.54759, acc: 0.85000\n",
      "[Train] Step: 51800, loss: 0.35346, acc: 0.90000\n",
      "[Train] Step: 51900, loss: 0.20060, acc: 0.90000\n",
      "[Train] Step: 52000, loss: 0.19934, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 52000, acc: 0.73150\n",
      "[Train] Step: 52100, loss: 0.33260, acc: 0.85000\n",
      "[Train] Step: 52200, loss: 0.20818, acc: 0.90000\n",
      "[Train] Step: 52300, loss: 0.35125, acc: 0.90000\n",
      "[Train] Step: 52400, loss: 0.36745, acc: 0.85000\n",
      "[Train] Step: 52500, loss: 0.45458, acc: 0.85000\n",
      "[Train] Step: 52600, loss: 0.22606, acc: 0.90000\n",
      "[Train] Step: 52700, loss: 0.38254, acc: 0.85000\n",
      "[Train] Step: 52800, loss: 0.12925, acc: 0.95000\n",
      "[Train] Step: 52900, loss: 0.11936, acc: 0.95000\n",
      "[Train] Step: 53000, loss: 0.21124, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 53000, acc: 0.73750\n",
      "[Train] Step: 53100, loss: 0.29778, acc: 0.85000\n",
      "[Train] Step: 53200, loss: 0.18174, acc: 0.90000\n",
      "[Train] Step: 53300, loss: 0.30452, acc: 0.90000\n",
      "[Train] Step: 53400, loss: 0.28281, acc: 0.95000\n",
      "[Train] Step: 53500, loss: 0.58788, acc: 0.80000\n",
      "[Train] Step: 53600, loss: 0.55783, acc: 0.75000\n",
      "[Train] Step: 53700, loss: 0.24682, acc: 0.85000\n",
      "[Train] Step: 53800, loss: 0.49251, acc: 0.95000\n",
      "[Train] Step: 53900, loss: 0.32550, acc: 0.90000\n",
      "[Train] Step: 54000, loss: 0.35638, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 54000, acc: 0.73900\n",
      "[Train] Step: 54100, loss: 0.46337, acc: 0.85000\n",
      "[Train] Step: 54200, loss: 0.23008, acc: 0.90000\n",
      "[Train] Step: 54300, loss: 0.50435, acc: 0.80000\n",
      "[Train] Step: 54400, loss: 0.52253, acc: 0.80000\n",
      "[Train] Step: 54500, loss: 0.62824, acc: 0.75000\n",
      "[Train] Step: 54600, loss: 0.25252, acc: 0.95000\n",
      "[Train] Step: 54700, loss: 0.48009, acc: 0.80000\n",
      "[Train] Step: 54800, loss: 0.16427, acc: 0.95000\n",
      "[Train] Step: 54900, loss: 0.47818, acc: 0.85000\n",
      "[Train] Step: 55000, loss: 0.28272, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 55000, acc: 0.73750\n",
      "[Train] Step: 55100, loss: 0.27630, acc: 0.90000\n",
      "[Train] Step: 55200, loss: 0.28758, acc: 0.90000\n",
      "[Train] Step: 55300, loss: 0.17911, acc: 0.95000\n",
      "[Train] Step: 55400, loss: 0.28669, acc: 0.90000\n",
      "[Train] Step: 55500, loss: 0.34375, acc: 0.90000\n",
      "[Train] Step: 55600, loss: 1.33322, acc: 0.65000\n",
      "[Train] Step: 55700, loss: 0.22031, acc: 0.95000\n",
      "[Train] Step: 55800, loss: 0.29464, acc: 0.85000\n",
      "[Train] Step: 55900, loss: 0.06532, acc: 1.00000\n",
      "[Train] Step: 56000, loss: 0.41376, acc: 0.75000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 56000, acc: 0.72850\n",
      "[Train] Step: 56100, loss: 0.28537, acc: 0.95000\n",
      "[Train] Step: 56200, loss: 0.37988, acc: 0.80000\n",
      "[Train] Step: 56300, loss: 0.14507, acc: 1.00000\n",
      "[Train] Step: 56400, loss: 0.51386, acc: 0.75000\n",
      "[Train] Step: 56500, loss: 0.32852, acc: 0.80000\n",
      "[Train] Step: 56600, loss: 0.52250, acc: 0.80000\n",
      "[Train] Step: 56700, loss: 0.19792, acc: 0.85000\n",
      "[Train] Step: 56800, loss: 0.73337, acc: 0.80000\n",
      "[Train] Step: 56900, loss: 0.71514, acc: 0.80000\n",
      "[Train] Step: 57000, loss: 0.29701, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 57000, acc: 0.73450\n",
      "[Train] Step: 57100, loss: 0.74110, acc: 0.75000\n",
      "[Train] Step: 57200, loss: 0.14252, acc: 0.95000\n",
      "[Train] Step: 57300, loss: 0.40550, acc: 0.90000\n",
      "[Train] Step: 57400, loss: 0.23858, acc: 0.85000\n",
      "[Train] Step: 57500, loss: 0.23631, acc: 0.85000\n",
      "[Train] Step: 57600, loss: 0.24239, acc: 0.90000\n",
      "[Train] Step: 57700, loss: 0.41951, acc: 0.85000\n",
      "[Train] Step: 57800, loss: 0.49341, acc: 0.85000\n",
      "[Train] Step: 57900, loss: 0.49620, acc: 0.80000\n",
      "[Train] Step: 58000, loss: 0.53489, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 58000, acc: 0.74350\n",
      "[Train] Step: 58100, loss: 0.55359, acc: 0.90000\n",
      "[Train] Step: 58200, loss: 0.69834, acc: 0.70000\n",
      "[Train] Step: 58300, loss: 0.60662, acc: 0.80000\n",
      "[Train] Step: 58400, loss: 0.40623, acc: 0.85000\n",
      "[Train] Step: 58500, loss: 0.54542, acc: 0.75000\n",
      "[Train] Step: 58600, loss: 0.66299, acc: 0.70000\n",
      "[Train] Step: 58700, loss: 0.09391, acc: 0.95000\n",
      "[Train] Step: 58800, loss: 0.51777, acc: 0.75000\n",
      "[Train] Step: 58900, loss: 0.38768, acc: 0.75000\n",
      "[Train] Step: 59000, loss: 0.33603, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 59000, acc: 0.73950\n",
      "[Train] Step: 59100, loss: 0.13591, acc: 0.95000\n",
      "[Train] Step: 59200, loss: 0.33818, acc: 0.80000\n",
      "[Train] Step: 59300, loss: 0.40262, acc: 0.80000\n",
      "[Train] Step: 59400, loss: 0.21262, acc: 0.90000\n",
      "[Train] Step: 59500, loss: 0.39546, acc: 0.80000\n",
      "[Train] Step: 59600, loss: 0.64570, acc: 0.80000\n",
      "[Train] Step: 59700, loss: 0.37003, acc: 0.85000\n",
      "[Train] Step: 59800, loss: 0.22592, acc: 0.90000\n",
      "[Train] Step: 59900, loss: 0.44655, acc: 0.85000\n",
      "[Train] Step: 60000, loss: 0.86859, acc: 0.70000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 60000, acc: 0.73600\n",
      "[Train] Step: 60100, loss: 0.38060, acc: 0.90000\n",
      "[Train] Step: 60200, loss: 0.19432, acc: 0.90000\n",
      "[Train] Step: 60300, loss: 0.39912, acc: 0.85000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 60400, loss: 1.31027, acc: 0.65000\n",
      "[Train] Step: 60500, loss: 0.31935, acc: 0.85000\n",
      "[Train] Step: 60600, loss: 0.77485, acc: 0.75000\n",
      "[Train] Step: 60700, loss: 0.22015, acc: 0.90000\n",
      "[Train] Step: 60800, loss: 0.89240, acc: 0.70000\n",
      "[Train] Step: 60900, loss: 0.54738, acc: 0.85000\n",
      "[Train] Step: 61000, loss: 0.50158, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 61000, acc: 0.74200\n",
      "[Train] Step: 61100, loss: 0.22657, acc: 0.85000\n",
      "[Train] Step: 61200, loss: 0.30640, acc: 0.90000\n",
      "[Train] Step: 61300, loss: 0.39827, acc: 0.90000\n",
      "[Train] Step: 61400, loss: 0.21343, acc: 0.90000\n",
      "[Train] Step: 61500, loss: 0.36912, acc: 0.85000\n",
      "[Train] Step: 61600, loss: 0.32090, acc: 0.90000\n",
      "[Train] Step: 61700, loss: 0.60515, acc: 0.75000\n",
      "[Train] Step: 61800, loss: 0.18969, acc: 0.95000\n",
      "[Train] Step: 61900, loss: 0.48199, acc: 0.85000\n",
      "[Train] Step: 62000, loss: 0.27692, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 62000, acc: 0.73000\n",
      "[Train] Step: 62100, loss: 0.35132, acc: 0.85000\n",
      "[Train] Step: 62200, loss: 0.48191, acc: 0.90000\n",
      "[Train] Step: 62300, loss: 0.17883, acc: 0.95000\n",
      "[Train] Step: 62400, loss: 0.54974, acc: 0.85000\n",
      "[Train] Step: 62500, loss: 0.39328, acc: 0.85000\n",
      "[Train] Step: 62600, loss: 0.26933, acc: 0.95000\n",
      "[Train] Step: 62700, loss: 0.03740, acc: 1.00000\n",
      "[Train] Step: 62800, loss: 0.36270, acc: 0.80000\n",
      "[Train] Step: 62900, loss: 0.06103, acc: 1.00000\n",
      "[Train] Step: 63000, loss: 0.32314, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 63000, acc: 0.73200\n",
      "[Train] Step: 63100, loss: 0.37275, acc: 0.80000\n",
      "[Train] Step: 63200, loss: 0.21685, acc: 0.95000\n",
      "[Train] Step: 63300, loss: 0.35222, acc: 0.90000\n",
      "[Train] Step: 63400, loss: 0.46543, acc: 0.85000\n",
      "[Train] Step: 63500, loss: 0.12333, acc: 1.00000\n",
      "[Train] Step: 63600, loss: 0.45065, acc: 0.80000\n",
      "[Train] Step: 63700, loss: 0.51237, acc: 0.75000\n",
      "[Train] Step: 63800, loss: 0.32117, acc: 0.85000\n",
      "[Train] Step: 63900, loss: 0.07159, acc: 1.00000\n",
      "[Train] Step: 64000, loss: 0.90464, acc: 0.60000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 64000, acc: 0.73650\n",
      "[Train] Step: 64100, loss: 0.23668, acc: 0.90000\n",
      "[Train] Step: 64200, loss: 0.31160, acc: 0.85000\n",
      "[Train] Step: 64300, loss: 0.26156, acc: 0.90000\n",
      "[Train] Step: 64400, loss: 0.33805, acc: 0.85000\n",
      "[Train] Step: 64500, loss: 0.22297, acc: 0.90000\n",
      "[Train] Step: 64600, loss: 0.43271, acc: 0.80000\n",
      "[Train] Step: 64700, loss: 0.87845, acc: 0.80000\n",
      "[Train] Step: 64800, loss: 0.34408, acc: 0.85000\n",
      "[Train] Step: 64900, loss: 0.42113, acc: 0.80000\n",
      "[Train] Step: 65000, loss: 0.42708, acc: 0.85000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 65000, acc: 0.72200\n",
      "[Train] Step: 65100, loss: 0.31968, acc: 0.85000\n",
      "[Train] Step: 65200, loss: 0.38482, acc: 0.90000\n",
      "[Train] Step: 65300, loss: 0.35513, acc: 0.80000\n",
      "[Train] Step: 65400, loss: 0.31579, acc: 0.90000\n",
      "[Train] Step: 65500, loss: 0.21554, acc: 0.90000\n",
      "[Train] Step: 65600, loss: 0.71093, acc: 0.75000\n",
      "[Train] Step: 65700, loss: 0.38815, acc: 0.80000\n",
      "[Train] Step: 65800, loss: 0.28466, acc: 0.90000\n",
      "[Train] Step: 65900, loss: 0.15810, acc: 0.95000\n",
      "[Train] Step: 66000, loss: 0.45201, acc: 0.80000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 66000, acc: 0.74100\n",
      "[Train] Step: 66100, loss: 0.24097, acc: 0.95000\n",
      "[Train] Step: 66200, loss: 0.69004, acc: 0.80000\n",
      "[Train] Step: 66300, loss: 0.17106, acc: 0.90000\n",
      "[Train] Step: 66400, loss: 0.41422, acc: 0.95000\n",
      "[Train] Step: 66500, loss: 0.26924, acc: 0.80000\n",
      "[Train] Step: 66600, loss: 0.68556, acc: 0.75000\n",
      "[Train] Step: 66700, loss: 0.34555, acc: 0.90000\n",
      "[Train] Step: 66800, loss: 0.75576, acc: 0.75000\n",
      "[Train] Step: 66900, loss: 0.98536, acc: 0.70000\n",
      "[Train] Step: 67000, loss: 0.17795, acc: 0.95000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 67000, acc: 0.73750\n",
      "[Train] Step: 67100, loss: 0.67748, acc: 0.85000\n",
      "[Train] Step: 67200, loss: 0.12259, acc: 0.95000\n",
      "[Train] Step: 67300, loss: 0.18204, acc: 0.95000\n",
      "[Train] Step: 67400, loss: 0.37906, acc: 0.90000\n",
      "[Train] Step: 67500, loss: 0.47460, acc: 0.90000\n",
      "[Train] Step: 67600, loss: 0.29961, acc: 0.90000\n",
      "[Train] Step: 67700, loss: 0.44723, acc: 0.85000\n",
      "[Train] Step: 67800, loss: 0.38925, acc: 0.80000\n",
      "[Train] Step: 67900, loss: 0.39850, acc: 0.85000\n",
      "[Train] Step: 68000, loss: 0.23967, acc: 0.90000\n",
      "(10000, 3072)\n",
      "(10000,)\n",
      "[Test ] Step: 68000, acc: 0.74050\n",
      "[Train] Step: 68100, loss: 0.49871, acc: 0.80000\n",
      "[Train] Step: 68200, loss: 0.07086, acc: 1.00000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c81009cf3d09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[Train] Step: %d, loss: %4.5f, acc: %4.5f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Charles\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 定义 init函数，执行初始化\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = 20\n",
    "train_steps = 100000\n",
    "test_steps = 100\n",
    "# session，打开session后执行计算图\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(train_steps):\n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run([loss, accuracy, train_op], feed_dict={x: batch_data, y: batch_labels})\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' % (i+1, loss_val, acc_val))\n",
    "        if (i+1) % 1000 == 0:\n",
    "            test_data = CifarData(test_filenames, False)\n",
    "            all_test_acc_val = []\n",
    "            for j in range(test_steps):\n",
    "                test_batch_data, test_batch_labels = test_data.next_batch(batch_size)\n",
    "                test_acc_val = sess.run([accuracy], feed_dict={x: test_batch_data, y: test_batch_labels})\n",
    "                all_test_acc_val.append(test_acc_val)\n",
    "            test_acc = np.mean(all_test_acc_val)\n",
    "            print('[Test ] Step: %d, acc: %4.5f' % (i+1, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
