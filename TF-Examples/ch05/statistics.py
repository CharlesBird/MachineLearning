# æ•°æ®ç»Ÿè®¡
import tensorflow as tf
import numpy as np

# å‘é‡èŒƒæ•°
x = tf.ones([2, 2])
print(tf.norm(x, ord=1))  # L1 èŒƒæ•°ï¼Œå®šä¹‰ä¸ºå‘é‡ğ’™çš„æ‰€æœ‰å…ƒç´ ç»å¯¹å€¼ä¹‹å’Œ

print(tf.norm(x, ord=2))  # L2 èŒƒæ•°ï¼Œå®šä¹‰ä¸ºå‘é‡ğ’™çš„æ‰€æœ‰å…ƒç´ çš„å¹³æ–¹å’Œï¼Œå†å¼€æ ¹å·

print(tf.norm(x, ord=np.inf))  # âˆ âˆ’èŒƒæ•°ï¼Œå®šä¹‰ä¸ºå‘é‡ğ’™çš„æ‰€æœ‰å…ƒç´ ç»å¯¹å€¼çš„æœ€å¤§å€¼


# æœ€å¤§æœ€å°å€¼ã€å‡å€¼ã€å’Œ
x = tf.random.uniform([4, 10])
print(x)
print(tf.reduce_max(x, axis=1))  # ç»Ÿè®¡æ¦‚ç‡ç»´åº¦ä¸Šçš„æœ€å¤§å€¼
print(tf.reduce_max(x, axis=0))

print(tf.reduce_min(x, axis=1))  # ç»Ÿè®¡æ¦‚ç‡ç»´åº¦ä¸Šçš„æœ€å°å€¼

print(tf.reduce_mean(x, axis=1))  # ç»Ÿè®¡æ¦‚ç‡ç»´åº¦ä¸Šçš„å‡å€¼

# å½“ä¸æŒ‡å®š axis å‚æ•°æ—¶ï¼Œtf.reduce_*å‡½æ•°ä¼šæ±‚è§£å‡ºå…¨å±€å…ƒç´ çš„æœ€å¤§ã€æœ€å°ã€å‡å€¼ã€å’Œï¼š
print(tf.reduce_max(x), tf.reduce_min(x), tf.reduce_mean(x))

# é€šè¿‡ TensorFlow çš„ MSE è¯¯å·®å‡½æ•°å¯ä»¥æ±‚å¾—æ¯ä¸ªæ ·æœ¬çš„è¯¯å·®ï¼Œéœ€è¦è®¡ç®—æ ·æœ¬çš„å¹³å‡è¯¯å·®ï¼Œ
# æ­¤æ—¶å¯ä»¥é€šè¿‡ tf.reduce_mean åœ¨æ ·æœ¬æ•°ç»´åº¦ä¸Šè®¡ç®—å‡å€¼
out = tf.random.normal([4, 10])  # ç½‘ç»œé¢„æµ‹è¾“å‡º
y = tf.constant([1, 2, 2, 0])  # çœŸå®æ ‡ç­¾
y = tf.one_hot(y, depth=10)  # one-hot ç¼–ç 
loss = tf.keras.losses.mse(y, out)  # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„è¯¯å·®
loss = tf.reduce_mean(loss)  # å¹³å‡è¯¯å·®
print(loss)

print(tf.reduce_sum(out, axis=-1))  # æ±‚å’Œ
print(tf.reduce_sum(out, axis=1))  # æ±‚å’Œ

out = tf.random.normal([2, 10])
print(out)
out = tf.nn.softmax(out, axis=1)  # é€šè¿‡ softmax è½¬æ¢ä¸ºæ¦‚ç‡å€¼
print(out)
# é€šè¿‡ tf.argmax(x, axis)ï¼Œtf.argmin(x, axis)å¯ä»¥æ±‚è§£åœ¨ axis è½´ä¸Šï¼Œx çš„æœ€å¤§å€¼ã€æœ€å°å€¼æ‰€åœ¨çš„ç´¢å¼•å·
pred = tf.argmax(out, axis=1)  # é€‰å–æ¦‚ç‡æœ€å¤§çš„ä½ç½®
print(pred)
